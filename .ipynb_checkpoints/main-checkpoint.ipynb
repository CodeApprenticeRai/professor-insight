{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-f6dd4655ef88>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSTOPWORDS\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "#Professor Insight Word Map for RateMyProfessor \n",
    "#5 Main Objectives\n",
    "\n",
    "#Objective 1: Isolate all comments\n",
    "#Objective 2: Isolate adjective words and phrases \n",
    "#Objective 3: Frequency Analysis\n",
    "#Objective 4: Generating the Word Map \n",
    "#Objective 5: Building the Web Page \n",
    "\n",
    "\n",
    "import requests\n",
    "import nltk\n",
    "import collections\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tare\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html5lib\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file c:\\users\\tare\\appdata\\local\\programs\\python\\python36-32\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"html5lib\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "#Objective 1: Isolate all comments\n",
    "#To get all comments I need to find the GET address and query it for all comments. \n",
    "\n",
    "##TO DO:\n",
    "### Find GET address with comment information\n",
    "### Query address for comment information\n",
    "### Tie Webpage to a variable set by webform input\n",
    "\n",
    "#So far I'm able to scrape the html for the first 20 comments\n",
    "\n",
    "\n",
    "webpage = \"http://www.ratemyprofessors.com/ShowRatings.jsp?tid=433738\"\n",
    "\n",
    "with requests.Session() as s:\n",
    "\ts.headers.update({\"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64)\"})\n",
    "\tsoup = BeautifulSoup(s.get(webpage).content)\n",
    "\tyes = soup.find_all('p','commentsParagraph')\n",
    "\t#json_data = yes.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Objective 2: Isolate adjective words and phrases\n",
    "text = [i.string for i in yes]\n",
    "tt = [nltk.word_tokenize(i) for i in text]\n",
    "ttt = [nltk.pos_tag(i) for i in tt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['difficult',\n",
       " 'everyday',\n",
       " 'able',\n",
       " 'good',\n",
       " 'boyfriend',\n",
       " 'great',\n",
       " 'sure',\n",
       " 'hard',\n",
       " 'high',\n",
       " 'first',\n",
       " 'much',\n",
       " 'great',\n",
       " 'other',\n",
       " 'calc',\n",
       " 'able',\n",
       " 'great',\n",
       " 'Differential',\n",
       " 'much',\n",
       " 'horrendous',\n",
       " 'math-minded',\n",
       " 'comprehend',\n",
       " 'long',\n",
       " 'irrelevant',\n",
       " 'necessary',\n",
       " 'winded',\n",
       " 'good',\n",
       " 'funny',\n",
       " 'smart',\n",
       " 'funny',\n",
       " 'smart',\n",
       " 'survivable',\n",
       " 'few',\n",
       " 'long',\n",
       " 'funny',\n",
       " 'good',\n",
       " 'amazing',\n",
       " 'silly',\n",
       " 'quick',\n",
       " 'rude',\n",
       " 'easy',\n",
       " 'diff',\n",
       " 'fair',\n",
       " 'simple',\n",
       " 'simple',\n",
       " 'entire',\n",
       " 'nice',\n",
       " 'diff',\n",
       " 'difficult',\n",
       " 'clear',\n",
       " 'little',\n",
       " 'tough',\n",
       " 'mandatory',\n",
       " 'extra',\n",
       " 'calc',\n",
       " 'good',\n",
       " 'several',\n",
       " 'everyday',\n",
       " 'final',\n",
       " 'tough',\n",
       " 'own',\n",
       " 'same',\n",
       " 'difficult',\n",
       " 'good',\n",
       " 'good',\n",
       " 'tough',\n",
       " 'nice',\n",
       " 'sure',\n",
       " 'graded',\n",
       " 'lengthy',\n",
       " 'possible']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Objective 2: Contd.\n",
    "\n",
    "#TO DO: \n",
    "### Find a solution for finding adjective phrases\n",
    "### Do some filtering on adjective words \n",
    "\n",
    "adjs = []\n",
    "adjs_excl = []\n",
    "for sent in ttt:\n",
    "    for word in sent:\n",
    "        if  (word[1] == 'JJ') or (word[1] == 'JJR') or (word[1] == 'JJS'): \n",
    "            adjs.append(word[0])\n",
    "\n",
    "for sent in ttt:\n",
    "    for word in sent:\n",
    "        if (word[1] == 'JJ'):\n",
    "            adjs_excl.append(word[0])\n",
    "\n",
    "adjs_excl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Differential': 1,\n",
       "         'able': 2,\n",
       "         'amazing': 1,\n",
       "         'boyfriend': 1,\n",
       "         'calc': 2,\n",
       "         'clear': 1,\n",
       "         'comprehend': 1,\n",
       "         'diff': 2,\n",
       "         'difficult': 3,\n",
       "         'easier': 1,\n",
       "         'easy': 1,\n",
       "         'entire': 1,\n",
       "         'everyday': 2,\n",
       "         'extra': 1,\n",
       "         'fair': 1,\n",
       "         'few': 1,\n",
       "         'final': 1,\n",
       "         'first': 1,\n",
       "         'funny': 3,\n",
       "         'good': 6,\n",
       "         'graded': 1,\n",
       "         'great': 3,\n",
       "         'hard': 1,\n",
       "         'high': 1,\n",
       "         'highest': 1,\n",
       "         'horrendous': 1,\n",
       "         'irrelevant': 1,\n",
       "         'lengthy': 1,\n",
       "         'little': 1,\n",
       "         'long': 2,\n",
       "         'mandatory': 1,\n",
       "         'math-minded': 1,\n",
       "         'most': 1,\n",
       "         'much': 2,\n",
       "         'necessary': 1,\n",
       "         'nice': 2,\n",
       "         'other': 1,\n",
       "         'own': 1,\n",
       "         'possible': 1,\n",
       "         'quick': 1,\n",
       "         'rude': 1,\n",
       "         'same': 1,\n",
       "         'several': 1,\n",
       "         'silly': 1,\n",
       "         'simple': 2,\n",
       "         'slower': 1,\n",
       "         'smart': 2,\n",
       "         'sure': 2,\n",
       "         'survivable': 1,\n",
       "         'tough': 3,\n",
       "         'toughest': 1,\n",
       "         'winded': 1,\n",
       "         'worst': 1})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_anylzd = collections.Counter(adjs)\n",
    "words_anylzd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Tags I've found\n",
    "#'has compassion for the student'\n",
    "#'genuinely wants to see students excell and understand the material'\n",
    "#''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'WordCloud' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-e539973ab6e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#Lots of Configurations it seems I'm going to have to learn though\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m wordcloud = WordCloud(font_path='/Users/kunal/Library/Fonts/sans-serif.ttf',\n\u001b[0m\u001b[0;32m     10\u001b[0m                           \u001b[0mstopwords\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSTOPWORDS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m                           \u001b[0mbackground_color\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'white'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'WordCloud' is not defined"
     ]
    }
   ],
   "source": [
    "#Objective 4: Generating the Word Map\n",
    "\n",
    "#TO-DO:\n",
    "### Learn to Configure worldcloud \n",
    "\n",
    "#Wordcloud library seems flexible enough for what I want \n",
    "#Lots of Configurations it seems I'm going to have to learn though\n",
    "\n",
    "#Example code. Far from what I need\n",
    "wordcloud = WordCloud(font_path='/Users/kunal/Library/Fonts/sans-serif.ttf',\n",
    "                          stopwords=STOPWORDS,\n",
    "                          background_color='white',\n",
    "                          width=1200,\n",
    "                          height=1000\n",
    "                         ).generate(text)\n",
    "\n",
    "\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Objective 5: Building the Web Page \n",
    "\n",
    "#I could use flask. If it makes sense. \n",
    "#I have a lot of dependencies, possibly may need to run from a server\n",
    "`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
